import matplotlib.pyplot as plt

Training_LMU_spike = [0.13651375, 0.44336128, 0.6490297, 0.7212555, 0.7708182, 0.7943126, 0.8062857, 0.8147967, 0.8191053, 0.8272595, 0.82877415, 0.83468854, 0.83611214, 0.8343735, 0.83719784]
Testing_LMU_spike =  [15.754730999469757, 28.87858748435974, 33.210280537605286, 36.651021242141724, 36.796969175338745, 38.58173191547394, 40.92929661273956, 40.06791710853577, 38.89365792274475, 40.75377881526947, 41.6542649269104, 41.72390103340149, 42.89434552192688, 40.75568616390228, 39.009082317352295, 39.009082317352295]

Training_LMU = [0.8258473, 0.90305364, 0.91439277, 0.9212031, 0.92797166, 0.9311073, 0.9307884, 0.9370558, 0.94197565, 0.94339544, 0.9433347, 0.9455896, 0.9494351, 0.95129526, 0.9543208]
Testing_LMU =  [87.66884207725525, 89.38015103340149, 89.34962749481201, 89.98779058456421, 89.0997052192688, 89.83516693115234, 88.80971670150757, 90.39892554283142, 88.80780935287476, 90.24152755737305, 90.53246974945068, 90.19383192062378, 90.61068892478943, 90.0574266910553, 90.15377163887024, 90.15377163887024]

Training_SNN = [0.65374076, 0.8242567, 0.82299256, 0.82899433, 0.8737587, 0.88673013, 0.8881727, 0.87918717, 0.8643745, 0.8757896, 0.89945865, 0.9100955, 0.91205055, 0.916511, 0.9091237]
Testing_SNN =  [80.4697036743164, 80.67097663879395, 82.14667439460754, 85.20776033401489, 84.85099673271179, 85.67517399787903, 83.79311561584473, 85.26308536529541, 84.33302640914917, 86.10443472862244, 87.00110912322998, 87.98363208770752, 87.31398582458496, 87.89396286010742, 86.40491366386414, 86.40491366386414]

Training_1_deep =  [[0.563058], [0.7937697], [0.825798], [0.83527696], [0.85147136], [0.8294309], [0.8598723], [0.87473804], [0.87515944], [0.8777598], [0.8748216], [0.8715037], [0.8650313], [0.86545646], [0.8765147], [0.87861395], [0.89252687], [0.87581617], [0.8550132], [0.87026995]]
Testing_1_deep =  [72.26133346557617, 77.00320482254028, 78.39495539665222, 80.82073926925659, 75.19650459289551, 82.16670751571655, 81.40453100204468, 81.26144409179688, 80.53361773490906, 78.84615659713745, 79.24965620040894, 79.11324501037598, 78.00480723381042, 79.81913685798645, 79.7256588935852, 79.73805665969849, 77.83024311065674, 76.26011371612549, 78.0353307723999, 79.38033938407898, 79.38033938407898]

Training_2_deep = [[0.3779724], [0.7210201], [0.7886715], [0.8007205], [0.81156236], [0.81317574], [0.792293], [0.78229773], [0.7751799], [0.7490168], [0.83113533], [0.8480055], [0.85073495], [0.85549915], [0.8559888], [0.8555029], [0.85388577], [0.852819], [0.8512664], [0.8536542]]
Testing_2_deep =  [59.82238054275513, 73.02445769309998, 75.01431107521057, 75.15453100204468, 73.9898145198822, 71.30647301673889, 72.86515831947327, 70.4708456993103, 70.26385068893433, 72.69154191017151, 72.85275459289551, 70.559561252594, 68.59356164932251, 68.39991807937622, 67.70547032356262, 67.32867956161499, 66.90705418586731, 66.1582350730896, 65.24248123168945, 64.77029919624329, 64.77029919624329]

Training_3_deep =  [[0.2242962], [0.6548682], [0.74195975], [0.74666315], [0.7513514], [0.7449359], [0.73601115], [0.7335778], [0.7248087], [0.698376], [0.5618433], [0.72870356], [0.7978924], [0.800246], [0.80274385], [0.80128616], [0.8031311], [0.8018138], [0.8011343], [0.79939944]]
Testing_3_deep = [49.151021242141724, 69.17162537574768, 70.1703667640686, 68.52392554283142, 68.68227124214172, 66.40338897705078, 67.92200803756714, 67.57478713989258, 66.71722531318665, 63.31177353858948, 32.12282657623291, 76.0111391544342, 76.58730149269104, 76.55200958251953, 76.12560987472534, 75.95199942588806, 75.47408938407898, 75.36439299583435, 74.78823065757751, 74.20921325683594, 74.20921325683594]

Training_1_reconnect = [[0.085053], [0.25431624], [0.33724716], [0.39387453], [0.44292092], [0.46957755], [0.49478027], [0.5152644], [0.54209566], [0.5663417], [0.5831397], [0.6058256], [0.6346081], [0.62791926], [0.65874785]]
Testing_1_reconnect =  [10.550213605165482, 17.126449942588806, 21.35893553495407, 25.34722089767456, 26.739928126335144, 29.62835729122162, 30.691009759902954, 33.62045884132385, 36.84466481208801, 36.90285384654999, 39.331501722335815, 42.03773736953735, 44.04761791229248, 43.12328398227692, 44.939520955085754,
44.939520955085754]

#Recurrent 1 out
#Training [[0.6754711], [0.82134116], [0.847671], [0.8463564], [0.8588564], [0.8717287], [0.86774313], [0.8683739], [0.8677394], [0.8731535], [0.8794263], [0.87919456], [0.8803495], [0.87722266], [0.88474166]]
#Testing [76.48841738700867, 80.75096607208252, 80.59749007225037, 83.11969041824341, 82.45753049850464, 82.64864683151245, 82.86486268043518, 82.33687281608582, 82.44208693504333, 83.95270109176636, 82.04054236412048, 85.21139025688171, 82.97587037086487, 83.59459638595581, 84.26158428192139, 84.26158428192139]


def make_plot(train_data, test_data, title):
    train_data = [x[0] for x in train_data]
    train_data = [i * 100 for i in train_data]
    plt.plot(range(1,len(train_data)+1), train_data, label="Training Accuracy")
    plt.plot(range(1,len(test_data)+1), test_data, label="Testing Accuracy")
    plt.xlabel("Epochs")
    plt.ylabel("% Accuracy")
    plt.title(title)
    plt.legend(loc="upper left")
    x1,x2,y1,y2 = plt.axis()
    plt.axis((x1,x2,0,100))
    plt.show()


#make_plot(Training_LMU_spike, Testing_LMU_spike, "Spiking LMU")
#make_plot(Training_LMU, Testing_LMU, "Regular LMU")
#make_plot(Training_SNN, Testing_SNN, "EnsembleArray")
#make_plot(Training_1_deep, Testing_1_deep, '1 Deep ensembleArray')
#make_plot(Training_2_deep, Testing_2_deep, '2 Deep ensembleArray')
#make_plot(Training_3_deep, Testing_3_deep, '3 Deep ensembleArray')
make_plot(Training_1_reconnect, Testing_1_reconnect, 'reconnect')
